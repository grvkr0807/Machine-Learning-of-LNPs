{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82a9aa57-f89a-4bc4-ae2d-b22f3efbe159",
   "metadata": {},
   "source": [
    "# Import Basic Libraries and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0667d004-b34d-4c56-8365-e03fc7f3ae64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from All_Featurizers import *\n",
    "from All_ML_Models import *\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d333eb52-070d-479a-a110-369198793065",
   "metadata": {},
   "source": [
    "# Inputs & Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e882f2c-128c-4eab-b71e-cac731a1356a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# featurizer_map={'RDKit':[RDKit_Descriptors_Featurizer, RDKit_FPGenerator_Featurizer, RDKit_AtomPairGenerator_Featurizer, RDKit_TopologicalTorsionGenerator_Featurizer],\n",
    "#                 'Descriptastorus': [Descriptastorus_MorganCounts_Featurizer, Descriptastorus_ChiralMorganCounts_Featurizer, Descriptastorus_FeatureCounts_Featurizer, Descriptastorus_AtomPairCounts_Featurizer, Descriptastorus_RDKitFPBits_Featurizer, Descriptastorus_RDKitFPUnbranched_Featurizer, Descriptastorus_RDKit2D_Featurizer, Descriptastorus_RDKit2DNormalized_Featurizer],\n",
    "#                 'DGL': [DGL_Mol2Bigraph_Featurizer, DGL_Mol2CompleteGraph_Featurizer],\n",
    "#                 'Pytorch': [PytorchGeometric_Featurizer],\n",
    "#                 'Hyperparameter': [RDKit_Descriptors_Featurizer],\n",
    "#                 'All_Unique': [RDKit_Descriptors_Featurizer, RDKit_FPGenerator_Featurizer, RDKit_AtomPairGenerator_Featurizer, Descriptastorus_MorganCounts_Featurizer, Descriptastorus_RDKit2DNormalized_Featurizer, DGL_Mol2CompleteGraph_Featurizer, PytorchGeometric_Featurizer],\n",
    "#                 'DeepChem': [DeepChem_ConvMol_Featurizer, DeepChem_Weave_Featurizer, DeepChem_CircularFP_Featurizer, DeepChem_MACCS_Featurizer, DeepChem_MolGraphConv_Featurizer, DeepChem_DMPNN_Featurizer, DeepChem_PAGTN_Featurizer]\n",
    "#                }\n",
    "featurizer_map={'RDKit':[RDKit_Descriptors_Featurizer, RDKit_FPGenerator_Featurizer, RDKit_AtomPairGenerator_Featurizer],\n",
    "                'Descriptastorus': [Descriptastorus_MorganCounts_Featurizer, Descriptastorus_RDKit2DNormalized_Featurizer],\n",
    "                'Pytorch': [PytorchGeometric_Featurizer],\n",
    "                'Hyperparameter': [RDKit_Descriptors_Featurizer],\n",
    "                'All_Unique': [RDKit_Descriptors_Featurizer, RDKit_FPGenerator_Featurizer, RDKit_AtomPairGenerator_Featurizer, Descriptastorus_MorganCounts_Featurizer, Descriptastorus_RDKit2DNormalized_Featurizer, PytorchGeometric_Featurizer],\n",
    "                'DeepChem': [DeepChem_CircularFP_Featurizer, DeepChem_MACCS_Featurizer, DeepChem_PAGTN_Featurizer]\n",
    "               }\n",
    "\n",
    "\n",
    "# data_splitter_map= {'Train_Test_Data_Splitter': [Train_Test_Data_Splitter],\n",
    "#                     'K_Fold_Data_Splitter': [K_Fold_Data_Splitter],\n",
    "#                     'SK_Fold_Data_Splitter': [SK_Fold_Data_Splitter],\n",
    "#                     'GK_Fold_Data_Splitter': [GK_Fold_Data_Splitter],\n",
    "#                     'LOOCV_Data_Splitter': [LOOCV_Data_Splitter],\n",
    "#                    }\n",
    "# \n",
    "# \n",
    "# classification_model_map= {'Binary_Classifier': [Binary_Classifier],\n",
    "#                           'MultiClass_Classifier': [MultiClass_Classifier],\n",
    "#                           'Probabilistic_Classifier': [Probabilistic_Classifier]\n",
    "#                           }\n",
    "\n",
    "ml_model_map= {'ML_Model_RF_Regression':[ML_Model_RF_Regression],\n",
    "               'ML_Model_RF_Classification':[ML_Model_RF_Classification],\n",
    "               'ML_Model_SVM_Classification':[ML_Model_SVM_Classification],\n",
    "               'ML_Model_kNN_Classification':[ML_Model_kNN_Classification],\n",
    "               'ML_Model_GB_Classification':[ML_Model_GB_Classification],\n",
    "               'ML_Model_LR_Classification':[ML_Model_LR_Classification],\n",
    "               'All_Classification_Models':[ML_Model_RF_Classification, ML_Model_SVM_Classification, ML_Model_kNN_Classification, ML_Model_GB_Classification, ML_Model_LR_Classification]\n",
    "              }\n",
    "\n",
    "\n",
    "# Names of files that contain SMILES, composition, and target property \n",
    "smiles_file = r\"C:\\Users\\grvkr\\Box\\Gaurav Kumar\\Purdue_Work\\SAR_NM\\Data\\Data_Combined\\Cell_Viability\\InVitro_SMILES.xlsx\"\n",
    "smiles_sheet_name= \"SMILES\"\n",
    "target_file = r\"C:\\Users\\grvkr\\Box\\Gaurav Kumar\\Purdue_Work\\SAR_NM\\Data\\Data_Combined\\Cell_Viability\\InVitro_Cell_Viability.xlsx\"\n",
    "target_sheet_name= \"2 bins\"\n",
    "output_file = r\"C:\\Users\\grvkr\\Box\\Gaurav Kumar\\Purdue_Work\\SAR_NM\\Results\\Data_Combined\\Cell_Viability\\Classification Report 2 bins.xlsx\"\n",
    "\n",
    "cr_sheet_name= 'Classification Report'   # sheet for classification report\n",
    "accuracy_sheet_name= \"Class Accuracies\"\n",
    "precision_sheet_name= \"Class Precision\"\n",
    "recall_sheet_name= \"Class Recall\"\n",
    "f1score_sheet_name= \"Class F1-Score\"\n",
    "ypred_sheet_name= 'Predicted Y Test'   # sheet for predicted y test\n",
    "ypred_full_sheet_name= 'Predicted Y Full'   # sheet for predicted y full\n",
    "\n",
    "\n",
    "featurizer_style= 'All_Unique'\n",
    "ml_model_style= 'All_Classification_Models'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b730591-f0bf-4742-93a3-9a329ad522a8",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39ac82f2-fdcb-4d79-82b4-7f93fe57df1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_df = pd.read_excel(smiles_file, sheet_name= smiles_sheet_name)\n",
    "target_df = pd.read_excel(target_file, sheet_name= target_sheet_name)\n",
    "\n",
    "Nrows, Ncolumns = smiles_df.shape\n",
    "Nconstituents= (Ncolumns-1)//2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d8bab8-591c-4156-8210-7cf2132eea71",
   "metadata": {},
   "source": [
    "# Implementation >>>>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170729f0-6a2c-4404-b27e-ecc676c0d2b3",
   "metadata": {},
   "source": [
    "# Featurization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61c1cfb0-c76c-4247-bd56-f9e085090357",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No normalization for SPS\n",
      "WARNING:root:No normalization for BCUT2D_MWHI\n",
      "WARNING:root:No normalization for BCUT2D_MWLOW\n",
      "WARNING:root:No normalization for BCUT2D_CHGHI\n",
      "WARNING:root:No normalization for BCUT2D_CHGLO\n",
      "WARNING:root:No normalization for BCUT2D_LOGPHI\n",
      "WARNING:root:No normalization for BCUT2D_LOGPLOW\n",
      "WARNING:root:No normalization for BCUT2D_MRHI\n",
      "WARNING:root:No normalization for BCUT2D_MRLOW\n",
      "WARNING:root:No normalization for AvgIpc\n"
     ]
    }
   ],
   "source": [
    "# Initialize dictionaries to store the output\n",
    "dataX_dict = {}\n",
    "datay_dict = {}\n",
    "\n",
    "# Iterate over the featurizer functions based on the featurizer_style\n",
    "for ff in featurizer_map[featurizer_style]:\n",
    "    # Call the function\n",
    "    dataX, datay = ff(smiles_df, target_df, Nrows, Nconstituents)\n",
    "    \n",
    "    # Store the output in the dictionaries with a unique key\n",
    "    featurizer_name = ff.__name__  # Get the featurizer function name\n",
    "    dataX_dict[featurizer_name] = dataX\n",
    "    datay_dict[featurizer_name] = datay\n",
    "\n",
    "\n",
    "# Create the filename using the featurizer_name variable\n",
    "filename = f\"dataX_dict_2bins_{featurizer_style}.pkl\"\n",
    "# Save the variable to a file\n",
    "with open(rf\"C:\\Users\\grvkr\\Box\\Gaurav Kumar\\Purdue_Work\\SAR_NM\\Scripts\\ML_Framework\\Data_Combined\\Cell_Viability_pickle_files\\{filename}\", 'wb') as file:\n",
    "    pickle.dump(dataX_dict, file)\n",
    "\n",
    "filename = f\"datay_dict_2bins_{featurizer_style}.pkl\"\n",
    "# Save the variable to a file\n",
    "with open(rf\"C:\\Users\\grvkr\\Box\\Gaurav Kumar\\Purdue_Work\\SAR_NM\\Scripts\\ML_Framework\\Data_Combined\\Cell_Viability_pickle_files\\{filename}\", 'wb') as file:\n",
    "    pickle.dump(datay_dict, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d05cc299-7d18-4e94-9ca7-9dbc57c7717c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the filename using the featurizer_name variable\n",
    "# filename = f\"dataX_dict_2bins_{featurizer_style}.pkl\"\n",
    "# # Save the variable to a file\n",
    "# with open(rf\"C:\\Users\\grvkr\\Box\\Gaurav Kumar\\Purdue_Work\\SAR_NM\\Scripts\\ML_Framework\\Data_Combined\\Cell_Viability_pickle_files\\{filename}\", 'rb') as file:\n",
    "#     dataX_dict= pickle.load(file)\n",
    "\n",
    "# filename = f\"datay_dict_2bins_{featurizer_style}.pkl\"\n",
    "# # Save the variable to a file\n",
    "# with open(rf\"C:\\Users\\grvkr\\Box\\Gaurav Kumar\\Purdue_Work\\SAR_NM\\Scripts\\ML_Framework\\Data_Combined\\Cell_Viability_pickle_files\\{filename}\", 'rb') as file:\n",
    "#     datay_dict= pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3b17aa-acd4-4207-8e93-a08ae260011c",
   "metadata": {},
   "source": [
    "# Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67955cfc-dc74-4846-a5e8-d507446dfa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Inputs parameters for Train-Test Data Splitting\n",
    "test_ratio= 0.20\n",
    "num_random= 42\n",
    "\n",
    "# Initialize dictionaries to store the output\n",
    "dataX_train_dict = {}\n",
    "dataX_test_dict = {}\n",
    "datay_train_dict = {}\n",
    "datay_test_dict = {}\n",
    "\n",
    "# Iterate over the functions based on the featurizer_style\n",
    "for ff in featurizer_map[featurizer_style]:\n",
    "    featurizer_name = ff.__name__  # Get the featurizer function name\n",
    "    \n",
    "    dataX_train, dataX_test, datay_train, datay_test= train_test_split(dataX_dict[featurizer_name], datay_dict[featurizer_name], test_size= test_ratio, random_state= num_random)\n",
    "    \n",
    "    # Store the output in the dictionaries with a unique key\n",
    "    dataX_train_dict[featurizer_name] = dataX_train\n",
    "    dataX_test_dict[featurizer_name] = dataX_test\n",
    "    datay_train_dict[featurizer_name] = datay_train\n",
    "    datay_test_dict[featurizer_name] = datay_test\n",
    "\n",
    "filename = f\"dataX_train_dict_2bins_{featurizer_style}.pkl\"\n",
    "# Save the variable to a file\n",
    "with open(rf\"C:\\Users\\grvkr\\Box\\Gaurav Kumar\\Purdue_Work\\SAR_NM\\Scripts\\ML_Framework\\Data_Combined\\Cell_Viability_pickle_files\\{filename}\", 'wb') as file:\n",
    "    pickle.dump(dataX_train_dict, file)\n",
    "    \n",
    "filename = f\"datay_train_dict_2bins_{featurizer_style}.pkl\"\n",
    "# Save the variable tdataX_train_dicto a file\n",
    "with open(rf\"C:\\Users\\grvkr\\Box\\Gaurav Kumar\\Purdue_Work\\SAR_NM\\Scripts\\ML_Framework\\Data_Combined\\Cell_Viability_pickle_files\\{filename}\", 'wb') as file:\n",
    "    pickle.dump(datay_train_dict, file)\n",
    "\n",
    "filename = f\"dataX_test_dict_2bins_{featurizer_style}.pkl\"\n",
    "# Save the variable to a file\n",
    "with open(rf\"C:\\Users\\grvkr\\Box\\Gaurav Kumar\\Purdue_Work\\SAR_NM\\Scripts\\ML_Framework\\Data_Combined\\Cell_Viability_pickle_files\\{filename}\", 'wb') as file:\n",
    "    pickle.dump(dataX_test_dict, file)\n",
    "\n",
    "filename = f\"datay_test_dict_2bins_{featurizer_style}.pkl\"\n",
    "# Save the variable to a file\n",
    "with open(rf\"C:\\Users\\grvkr\\Box\\Gaurav Kumar\\Purdue_Work\\SAR_NM\\Scripts\\ML_Framework\\Data_Combined\\Cell_Viability_pickle_files\\{filename}\", 'wb') as file:\n",
    "    pickle.dump(datay_test_dict, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e2de015-334b-470b-a80a-946ca0ac8b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = f\"dataX_train_dict_2bins_{featurizer_style}.pkl\"\n",
    "# # Save the variable to a file\n",
    "# with open(rf\"C:\\Users\\grvkr\\Box\\Gaurav Kumar\\Purdue_Work\\SAR_NM\\Scripts\\ML_Framework\\Data_Combined\\Activity_pickle_files\\{filename}\", 'rb') as file:\n",
    "#     dataX_train_dict= pickle.load(file)\n",
    "    \n",
    "# filename = f\"datay_train_dict_2bins_{featurizer_style}.pkl\"\n",
    "# # Save the variable tdataX_train_dicto a file\n",
    "# with open(rf\"C:\\Users\\grvkr\\Box\\Gaurav Kumar\\Purdue_Work\\SAR_NM\\Scripts\\ML_Framework\\Data_Combined\\Activity_pickle_files\\{filename}\", 'rb') as file:\n",
    "#     datay_train_dict= pickle.load(file)\n",
    "\n",
    "# filename = f\"dataX_test_dict_2bins_{featurizer_style}.pkl\"\n",
    "# # Save the variable to a file\n",
    "# with open(rf\"C:\\Users\\grvkr\\Box\\Gaurav Kumar\\Purdue_Work\\SAR_NM\\Scripts\\ML_Framework\\Data_Combined\\Activity_pickle_files\\{filename}\", 'rb') as file:\n",
    "#     dataX_test_dict= pickle.load(file)\n",
    "\n",
    "# filename = f\"datay_test_dict_2bins_{featurizer_style}.pkl\"\n",
    "# # Save the variable to a file\n",
    "# with open(rf\"C:\\Users\\grvkr\\Box\\Gaurav Kumar\\Purdue_Work\\SAR_NM\\Scripts\\ML_Framework\\Data_Combined\\Activity_pickle_files\\{filename}\", 'rb') as file:\n",
    "#     datay_test_dict= pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d633466f-fc24-45d1-b586-a7a4fa22aeac",
   "metadata": {},
   "source": [
    "# ML model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae82edcf-b303-4fa2-a729-0faeb37ed484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for ML model training\n",
    "num_estimators= 200\n",
    "num_neighbors= 5\n",
    "num_random= 42\n",
    "\n",
    "\n",
    "# Initialize dictionaries to store the output\n",
    "datay_pred_dict = {}\n",
    "datay_pred_full_dict = {}\n",
    "\n",
    "# Iterate over the featurizer functions and ml model functions\n",
    "for ff in featurizer_map[featurizer_style]:\n",
    "    featurizer_name = ff.__name__  # Get the featurizer function name\n",
    "    for mm in ml_model_map[ml_model_style]:\n",
    "        ml_model_name = mm.__name__  # Get the ml model function name\n",
    "    \n",
    "        datay_pred, datay_pred_full= mm(dataX_dict[featurizer_name], dataX_train_dict[featurizer_name], dataX_test_dict[featurizer_name], datay_train_dict[featurizer_name], datay_test_dict[featurizer_name], num_estimators, num_neighbors, num_random)\n",
    "        \n",
    "        # Initialize the inner dictionary if it does not exist\n",
    "        if ml_model_name not in datay_pred_dict:\n",
    "            datay_pred_dict[ml_model_name] = {}\n",
    "        if ml_model_name not in datay_pred_full_dict:\n",
    "            datay_pred_full_dict[ml_model_name] = {}\n",
    "            \n",
    "        # Store the output in the dictionaries with a unique key\n",
    "        datay_pred_dict[ml_model_name][featurizer_name] = datay_pred\n",
    "        datay_pred_full_dict[ml_model_name][featurizer_name] = datay_pred_full\n",
    "\n",
    "filename = f\"datay_pred_dict_2bins_{featurizer_style}.pkl\"\n",
    "# Save the variable to a file\n",
    "with open(rf\"C:\\Users\\grvkr\\Box\\Gaurav Kumar\\Purdue_Work\\SAR_NM\\Scripts\\ML_Framework\\Data_Combined\\Cell_Viability_pickle_files\\{filename}\", 'wb') as file:\n",
    "    pickle.dump(datay_pred_dict, file)\n",
    "\n",
    "filename = f\"datay_pred_full_dict_2bins_{featurizer_style}.pkl\"\n",
    "# Save the variable to a file\n",
    "with open(rf\"C:\\Users\\grvkr\\Box\\Gaurav Kumar\\Purdue_Work\\SAR_NM\\Scripts\\ML_Framework\\Data_Combined\\Cell_Viability_pickle_files\\{filename}\", 'wb') as file:\n",
    "    pickle.dump(datay_pred_full_dict, file)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e01674fe-438b-4aeb-ab31-f92a60d77b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = f\"datay_pred_dict_2bins_{featurizer_style}.pkl\"\n",
    "# # Save the variable to a file\n",
    "# with open(rf\"C:\\Users\\grvkr\\Box\\Gaurav Kumar\\Purdue_Work\\SAR_NM\\Scripts\\ML_Framework\\Data_Combined\\Activity_pickle_files\\{filename}\", 'rb') as file:\n",
    "#     datay_pred_dict= pickle.load(file)\n",
    "\n",
    "# filename = f\"datay_pred_full_dict_2bins_{featurizer_style}.pkl\"\n",
    "# # Save the variable to a file\n",
    "# with open(rf\"C:\\Users\\grvkr\\Box\\Gaurav Kumar\\Purdue_Work\\SAR_NM\\Scripts\\ML_Framework\\Data_Combined\\Activity_pickle_files\\{filename}\", 'rb') as file:\n",
    "#     datay_pred_full_dict= pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a446a7-7346-434e-a2c0-ae482fbe1c57",
   "metadata": {},
   "source": [
    "# Write Classification Report to Excel File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d422f1c-9c76-4070-9ffe-14980605207f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Initialize an empty list to store all the rows\n",
    "all_rows = []\n",
    "\n",
    "# Iterate over the functions based on the featurizer_style to process classification report\n",
    "for mm in ml_model_map[ml_model_style]:\n",
    "    ml_model_name = mm.__name__  # Get the function name\n",
    "    for ff in featurizer_map[featurizer_style]:\n",
    "        featurizer_name = ff.__name__  # Get the function name\n",
    "\n",
    "        predictions= datay_pred_dict[ml_model_name][featurizer_name]\n",
    "        y_true = datay_test_dict[featurizer_name]\n",
    "\n",
    "        # Generate classification report\n",
    "        report_dict= classification_report(y_true, predictions, output_dict=True)\n",
    "        # Convert the classification report to a DataFrame\n",
    "        report_df = pd.DataFrame(report_dict).transpose()\n",
    "\n",
    "        # Flatten the DataFrame into a single row for headers and values\n",
    "        flattened_report = report_df.reset_index().melt(id_vars=['index'])\n",
    "        flattened_report.columns = ['Metric', 'Class', 'Value']\n",
    "        # Prepare headers and values for output\n",
    "        headers = flattened_report.apply(lambda row: f\"{row['Class']}_{row['Metric']}\", axis=1)\n",
    "        values = flattened_report['Value']\n",
    "        # Output headers and values as a single row\n",
    "        headers_row = headers.tolist()\n",
    "        headers_row = [\"ML Model Name\"] + [\"Featurizer Name\"] + headers_row\n",
    "        values_row = [ml_model_name] + [featurizer_name] + values.tolist()\n",
    "        \n",
    "        # Create a DataFrame with the headers and values as a single row\n",
    "        output_df = pd.DataFrame([values_row], columns=headers_row)\n",
    "        all_rows.append(output_df)\n",
    "\n",
    "# Concatenate all the rows into a single DataFrame\n",
    "new_data_df = pd.concat(all_rows, ignore_index=True)\n",
    "\n",
    "# Check if the output file exists and read existing data if it does\n",
    "if os.path.exists(output_file):\n",
    "    with pd.ExcelFile(output_file, engine='openpyxl') as xls:\n",
    "        if cr_sheet_name in xls.sheet_names:\n",
    "            existing_data_df = pd.read_excel(xls, sheet_name=cr_sheet_name)\n",
    "            # Concatenate existing data with new data\n",
    "            combined_df = pd.concat([existing_data_df, new_data_df], ignore_index=True)\n",
    "        else:\n",
    "            combined_df = new_data_df\n",
    "else:\n",
    "    combined_df = new_data_df\n",
    "\n",
    "with pd.ExcelWriter(output_file, engine='openpyxl', mode='a', if_sheet_exists= 'replace') as writer:\n",
    "    combined_df.to_excel(writer, sheet_name= cr_sheet_name, index=False)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Finished\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ba7dd1-5b08-45d1-8d8a-526b686c6113",
   "metadata": {},
   "source": [
    "# Write Predicted value to Excel File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed5d2779-7620-465d-a431-b2f943e4ae0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a DataFrame to store the predictions\n",
    "new_output_df = pd.DataFrame()\n",
    "column_name= 'y Test'\n",
    "new_output_df[column_name] = datay_test_dict[featurizer_name]\n",
    "# Iterate over the ml model functions and featurizer functions\n",
    "for ml_model_name, featurizers in datay_pred_dict.items():\n",
    "    for featurizer_name, predictions in featurizers.items():\n",
    "        # Create a column name based on ml_model_name and featurizer_name\n",
    "        column_name = f\"{ml_model_name}_{featurizer_name}\"\n",
    "        # Add the predictions to the DataFrame\n",
    "        new_output_df[column_name] = predictions\n",
    "# Check if the output file exists and read existing data if it does\n",
    "if os.path.exists(output_file):\n",
    "    with pd.ExcelFile(output_file, engine='openpyxl') as xls:\n",
    "        if ypred_sheet_name in xls.sheet_names:\n",
    "            existing_data_df = pd.read_excel(xls, sheet_name=ypred_sheet_name)\n",
    "            # Concatenate existing data with new data\n",
    "            combined_df = pd.concat([existing_data_df, new_output_df], axis=1)\n",
    "        else:\n",
    "            combined_df = new_output_df\n",
    "else:\n",
    "    combined_df = new_output_df\n",
    "\n",
    "# Write the combined DataFrame to the Excel file\n",
    "with pd.ExcelWriter(output_file, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    combined_df.to_excel(writer, sheet_name=ypred_sheet_name, index=False)\n",
    "\n",
    "\n",
    "\n",
    "# Initialize a DataFrame to store the predictions\n",
    "new_output_full_df = pd.DataFrame()\n",
    "column_name= 'y Full'\n",
    "new_output_full_df[column_name] = datay_dict[featurizer_name]\n",
    "# Iterate over the ml model functions and featurizer functions\n",
    "for ml_model_name, featurizers in datay_pred_full_dict.items():\n",
    "    for featurizer_name, predictions in featurizers.items():\n",
    "        # Create a column name based on ml_model_name and featurizer_name\n",
    "        column_name = f\"{ml_model_name}_{featurizer_name}\"\n",
    "        # Add the predictions to the DataFrame\n",
    "        new_output_full_df[column_name] = predictions\n",
    "# Check if the output file exists and read existing data if it does\n",
    "if os.path.exists(output_file):\n",
    "    with pd.ExcelFile(output_file, engine='openpyxl') as xls:\n",
    "        if ypred_sheet_name in xls.sheet_names:\n",
    "            existing_data_df = pd.read_excel(xls, sheet_name=ypred_full_sheet_name)\n",
    "            # Concatenate existing data with new data\n",
    "            combined_df = pd.concat([existing_data_df, new_output_full_df], axis=1)\n",
    "        else:\n",
    "            combined_df = new_output_full_df\n",
    "else:\n",
    "    combined_df = new_output_full_df\n",
    "\n",
    "# Write the combined DataFrame to the Excel file\n",
    "with pd.ExcelWriter(output_file, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    combined_df.to_excel(writer, sheet_name=ypred_full_sheet_name, index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee11d776-2abb-4c0f-9d57-69a5502304b3",
   "metadata": {},
   "source": [
    "# Calculate Accuracy for each class and Write to excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa7e9d54-5e44-4637-acd9-24a4a2d5e9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Calculate accuracy for each class\n",
    "\n",
    "\n",
    "# Initialize an empty dictionary to store the accuracies\n",
    "accuracy_dict = {}\n",
    "precision_dict = {}\n",
    "recall_dict = {}\n",
    "f1score_dict = {}\n",
    "\n",
    "# Iterate over the functions based on the featurizer_style to process classification report\n",
    "for mm in ml_model_map[ml_model_style]:\n",
    "    ml_model_name = mm.__name__  # Get the function name\n",
    "    accuracy_dict[ml_model_name] = {}\n",
    "    precision_dict[ml_model_name] = {}\n",
    "    recall_dict[ml_model_name] = {}\n",
    "    f1score_dict[ml_model_name] = {}\n",
    "    for ff in featurizer_map[featurizer_style]:\n",
    "        featurizer_name = ff.__name__  # Get the function name\n",
    "        predicted_class= datay_pred_dict[ml_model_name][featurizer_name]\n",
    "        true_class = datay_test_dict[featurizer_name]\n",
    "        \n",
    "        classes = np.unique(true_class)\n",
    "        accuracy_per_class = {}\n",
    "        precision_per_class = {}\n",
    "        recall_per_class = {}\n",
    "        f1score_per_class = {}\n",
    "        for cls in classes:\n",
    "            # Binary classification: 1 for current class, 0 for all other classes\n",
    "            y_true_binary = [1 if y == cls else 0 for y in true_class]\n",
    "            y_pred_binary = [1 if y == cls else 0 for y in predicted_class]\n",
    "            accuracy = accuracy_score(y_true_binary, y_pred_binary)\n",
    "            precision = precision_score(y_true_binary, y_pred_binary)\n",
    "            recall = recall_score(y_true_binary, y_pred_binary)\n",
    "            f1score = f1_score(y_true_binary, y_pred_binary)\n",
    "            \n",
    "            accuracy_per_class[cls] = accuracy\n",
    "            precision_per_class[cls] = precision\n",
    "            recall_per_class[cls] = recall\n",
    "            f1score_per_class[cls] = f1score\n",
    "\n",
    "        accuracy_dict[ml_model_name][featurizer_name] = accuracy_per_class\n",
    "        precision_dict[ml_model_name][featurizer_name] = precision_per_class\n",
    "        recall_dict[ml_model_name][featurizer_name] = recall_per_class\n",
    "        f1score_dict[ml_model_name][featurizer_name] = f1score_per_class\n",
    "\n",
    "# Convert the nested dictionary to a DataFrame\n",
    "accuracy_df = pd.DataFrame.from_dict({(i,j): accuracy_dict[i][j] \n",
    "                                       for i in accuracy_dict.keys() \n",
    "                                       for j in accuracy_dict[i].keys()},\n",
    "                                      orient='index')\n",
    "# Reset the index to make ml_model_name and featurizer_name columns\n",
    "accuracy_df.reset_index(inplace=True)\n",
    "accuracy_df.columns = ['ML Model Name', 'Featurizer Name'] + list(accuracy_df.columns[2:])\n",
    "\n",
    "\n",
    "precision_df = pd.DataFrame.from_dict({(i,j): precision_dict[i][j] \n",
    "                                       for i in precision_dict.keys() \n",
    "                                       for j in precision_dict[i].keys()},\n",
    "                                      orient='index')\n",
    "# Reset the index to make ml_model_name and featurizer_name columns\n",
    "precision_df.reset_index(inplace=True)\n",
    "precision_df.columns = ['ML Model Name', 'Featurizer Name'] + list(precision_df.columns[2:])\n",
    "\n",
    "\n",
    "recall_df = pd.DataFrame.from_dict({(i,j): recall_dict[i][j] \n",
    "                                       for i in recall_dict.keys() \n",
    "                                       for j in recall_dict[i].keys()},\n",
    "                                      orient='index')\n",
    "# Reset the index to make ml_model_name and featurizer_name columns\n",
    "recall_df.reset_index(inplace=True)\n",
    "recall_df.columns = ['ML Model Name', 'Featurizer Name'] + list(recall_df.columns[2:])\n",
    "\n",
    "\n",
    "f1score_df = pd.DataFrame.from_dict({(i,j): f1score_dict[i][j] \n",
    "                                       for i in f1score_dict.keys() \n",
    "                                       for j in f1score_dict[i].keys()},\n",
    "                                      orient='index')\n",
    "# Reset the index to make ml_model_name and featurizer_name columns\n",
    "f1score_df.reset_index(inplace=True)\n",
    "f1score_df.columns = ['ML Model Name', 'Featurizer Name'] + list(f1score_df.columns[2:])\n",
    "\n",
    "\n",
    "# Check if the output file exists and read existing data if it does\n",
    "if os.path.exists(output_file):\n",
    "    with pd.ExcelFile(output_file, engine='openpyxl') as xls:\n",
    "        if accuracy_sheet_name in xls.sheet_names:\n",
    "            existing_data_df = pd.read_excel(xls, sheet_name=accuracy_sheet_name)\n",
    "            # Concatenate existing data with new data\n",
    "            combined_df = pd.concat([existing_data_df, accuracy_df], ignore_index=True)\n",
    "        else:\n",
    "            combined_df = accuracy_df\n",
    "else:\n",
    "    combined_df = accuracy_df\n",
    "\n",
    "# Write the combined DataFrame to the Excel file\n",
    "with pd.ExcelWriter(output_file, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    combined_df.to_excel(writer, sheet_name=accuracy_sheet_name, index=False)\n",
    "\n",
    "\n",
    "# Check if the output file exists and read existing data if it does\n",
    "if os.path.exists(output_file):\n",
    "    with pd.ExcelFile(output_file, engine='openpyxl') as xls:\n",
    "        if precision_sheet_name in xls.sheet_names:\n",
    "            existing_data_df = pd.read_excel(xls, sheet_name=precision_sheet_name)\n",
    "            # Concatenate existing data with new data\n",
    "            combined_df = pd.concat([existing_data_df, precision_df], ignore_index=True)\n",
    "        else:\n",
    "            combined_df = precision_df\n",
    "else:\n",
    "    combined_df = precision_df\n",
    "\n",
    "# Write the combined DataFrame to the Excel file\n",
    "with pd.ExcelWriter(output_file, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    combined_df.to_excel(writer, sheet_name=precision_sheet_name, index=False)\n",
    "\n",
    "\n",
    "# Check if the output file exists and read existing data if it does\n",
    "if os.path.exists(output_file):\n",
    "    with pd.ExcelFile(output_file, engine='openpyxl') as xls:\n",
    "        if recall_sheet_name in xls.sheet_names:\n",
    "            existing_data_df = pd.read_excel(xls, sheet_name=recall_sheet_name)\n",
    "            # Concatenate existing data with new data\n",
    "            combined_df = pd.concat([existing_data_df, recall_df], ignore_index=True)\n",
    "        else:\n",
    "            combined_df = recall_df\n",
    "else:\n",
    "    combined_df = recall_df\n",
    "\n",
    "# Write the combined DataFrame to the Excel file\n",
    "with pd.ExcelWriter(output_file, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    combined_df.to_excel(writer, sheet_name=recall_sheet_name, index=False)\n",
    "\n",
    "\n",
    "# Check if the output file exists and read existing data if it does\n",
    "if os.path.exists(output_file):\n",
    "    with pd.ExcelFile(output_file, engine='openpyxl') as xls:\n",
    "        if f1score_sheet_name in xls.sheet_names:\n",
    "            existing_data_df = pd.read_excel(xls, sheet_name=f1score_sheet_name)\n",
    "            # Concatenate existing data with new data\n",
    "            combined_df = pd.concat([existing_data_df, f1score_df], ignore_index=True)\n",
    "        else:\n",
    "            combined_df = f1score_df\n",
    "else:\n",
    "    combined_df = f1score_df\n",
    "\n",
    "# Write the combined DataFrame to the Excel file\n",
    "with pd.ExcelWriter(output_file, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    combined_df.to_excel(writer, sheet_name=f1score_sheet_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5af89e-49dd-4de4-b575-a5aeba99d9ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
