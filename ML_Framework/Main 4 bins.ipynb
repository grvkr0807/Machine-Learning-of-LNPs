{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82a9aa57-f89a-4bc4-ae2d-b22f3efbe159",
   "metadata": {},
   "source": [
    "# Import Basic Libraries and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0667d004-b34d-4c56-8365-e03fc7f3ae64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from All_Featurizers import *\n",
    "from All_ML_Models import *\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d333eb52-070d-479a-a110-369198793065",
   "metadata": {},
   "source": [
    "# Inputs & Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e882f2c-128c-4eab-b71e-cac731a1356a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# featurizer_map={'RDKit':[RDKit_Descriptors_Featurizer, RDKit_FPGenerator_Featurizer, RDKit_AtomPairGenerator_Featurizer, RDKit_TopologicalTorsionGenerator_Featurizer],\n",
    "#                 'Descriptastorus': [Descriptastorus_MorganCounts_Featurizer, Descriptastorus_ChiralMorganCounts_Featurizer, Descriptastorus_FeatureCounts_Featurizer, Descriptastorus_AtomPairCounts_Featurizer, Descriptastorus_RDKitFPBits_Featurizer, Descriptastorus_RDKitFPUnbranched_Featurizer, Descriptastorus_RDKit2D_Featurizer, Descriptastorus_RDKit2DNormalized_Featurizer],\n",
    "#                 'DGL': [DGL_Mol2Bigraph_Featurizer, DGL_Mol2CompleteGraph_Featurizer],\n",
    "#                 'Pytorch': [PytorchGeometric_Featurizer],\n",
    "#                 'Hyperparameter': [RDKit_Descriptors_Featurizer],\n",
    "#                 'All_Unique': [RDKit_Descriptors_Featurizer, RDKit_FPGenerator_Featurizer, RDKit_AtomPairGenerator_Featurizer, Descriptastorus_MorganCounts_Featurizer, Descriptastorus_RDKit2DNormalized_Featurizer, DGL_Mol2CompleteGraph_Featurizer, PytorchGeometric_Featurizer],\n",
    "#                 'DeepChem': [DeepChem_ConvMol_Featurizer, DeepChem_Weave_Featurizer, DeepChem_CircularFP_Featurizer, DeepChem_MACCS_Featurizer, DeepChem_MolGraphConv_Featurizer, DeepChem_DMPNN_Featurizer, DeepChem_PAGTN_Featurizer]\n",
    "#                }\n",
    "featurizer_map={'RDKit':[RDKit_Descriptors_Featurizer, RDKit_FPGenerator_Featurizer, RDKit_AtomPairGenerator_Featurizer],\n",
    "                'Descriptastorus': [Descriptastorus_MorganCounts_Featurizer, Descriptastorus_RDKit2DNormalized_Featurizer],\n",
    "                'Pytorch': [PytorchGeometric_Featurizer],\n",
    "                'Hyperparameter': [RDKit_Descriptors_Featurizer],\n",
    "                'All_Unique': [RDKit_Descriptors_Featurizer, RDKit_FPGenerator_Featurizer, RDKit_AtomPairGenerator_Featurizer, Descriptastorus_MorganCounts_Featurizer, Descriptastorus_RDKit2DNormalized_Featurizer, PytorchGeometric_Featurizer],\n",
    "                'DeepChem': [DeepChem_CircularFP_Featurizer, DeepChem_MACCS_Featurizer, DeepChem_PAGTN_Featurizer]\n",
    "               }\n",
    "\n",
    "\n",
    "# data_splitter_map= {'Train_Test_Data_Splitter': [Train_Test_Data_Splitter],\n",
    "#                     'K_Fold_Data_Splitter': [K_Fold_Data_Splitter],\n",
    "#                     'SK_Fold_Data_Splitter': [SK_Fold_Data_Splitter],\n",
    "#                     'GK_Fold_Data_Splitter': [GK_Fold_Data_Splitter],\n",
    "#                     'LOOCV_Data_Splitter': [LOOCV_Data_Splitter],\n",
    "#                    }\n",
    "# \n",
    "# \n",
    "# classification_model_map= {'Binary_Classifier': [Binary_Classifier],\n",
    "#                           'MultiClass_Classifier': [MultiClass_Classifier],\n",
    "#                           'Probabilistic_Classifier': [Probabilistic_Classifier]\n",
    "#                           }\n",
    "\n",
    "ml_model_map= {'ML_Model_RF_Regression':[ML_Model_RF_Regression],\n",
    "               'ML_Model_RF_Classification':[ML_Model_RF_Classification],\n",
    "               'ML_Model_SVM_Classification':[ML_Model_SVM_Classification],\n",
    "               'ML_Model_kNN_Classification':[ML_Model_kNN_Classification],\n",
    "               'ML_Model_GB_Classification':[ML_Model_GB_Classification],\n",
    "               'ML_Model_LR_Classification':[ML_Model_LR_Classification],\n",
    "               'All_Classification_Models':[ML_Model_RF_Classification, ML_Model_SVM_Classification, ML_Model_kNN_Classification, ML_Model_GB_Classification, ML_Model_LR_Classification]\n",
    "              }\n",
    "\n",
    "\n",
    "# Names of files that contain SMILES, composition, and target property \n",
    "smiles_file = r\"C:\\Users\\grvkr\\Box\\Gaurav Kumar\\Purdue_Work\\SAR_NM\\Data\\Data_Combined\\Cell_Viability\\InVitro_SMILES.xlsx\"\n",
    "smiles_sheet_name= \"SMILES\"\n",
    "target_file = r\"C:\\Users\\grvkr\\Box\\Gaurav Kumar\\Purdue_Work\\SAR_NM\\Data\\Data_Combined\\Cell_Viability\\InVitro_Cell_Viability.xlsx\"\n",
    "target_sheet_name= \"4 bins\"\n",
    "output_file = r\"C:\\Users\\grvkr\\Box\\Gaurav Kumar\\Purdue_Work\\SAR_NM\\Results\\Data_Combined\\Cell_Viability\\Classification Report 4 bins.xlsx\"\n",
    "\n",
    "cr_sheet_name= 'Classification Report'   # sheet for classification report\n",
    "accuracy_sheet_name= \"Class Accuracies\"\n",
    "precision_sheet_name= \"Class Precision\"\n",
    "recall_sheet_name= \"Class Recall\"\n",
    "f1score_sheet_name= \"Class F1-Score\"\n",
    "ypred_sheet_name= 'Predicted Y Test'   # sheet for predicted y test\n",
    "ypred_full_sheet_name= 'Predicted Y Full'   # sheet for predicted y full\n",
    "\n",
    "\n",
    "featurizer_style= 'All_Unique'\n",
    "ml_model_style= 'All_Classification_Models'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b730591-f0bf-4742-93a3-9a329ad522a8",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39ac82f2-fdcb-4d79-82b4-7f93fe57df1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Worksheet named '4 bins' not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m smiles_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(smiles_file, sheet_name\u001b[38;5;241m=\u001b[39m smiles_sheet_name)\n\u001b[1;32m----> 2\u001b[0m target_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtarget_sheet_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m Nrows, Ncolumns \u001b[38;5;241m=\u001b[39m smiles_df\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m      5\u001b[0m Nconstituents\u001b[38;5;241m=\u001b[39m (Ncolumns\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch-env\\lib\\site-packages\\pandas\\io\\excel\\_base.py:486\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    480\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    481\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    482\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    483\u001b[0m     )\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrue_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrue_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfalse_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfalse_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mna_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_default_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_default_na\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mna_filter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_filter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_parser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthousands\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthousands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskipfooter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipfooter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    509\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;66;03m# make sure to close opened file handles\u001b[39;00m\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m should_close:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch-env\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1551\u001b[0m, in \u001b[0;36mExcelFile.parse\u001b[1;34m(self, sheet_name, header, names, index_col, usecols, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, date_format, thousands, comment, skipfooter, dtype_backend, **kwds)\u001b[0m\n\u001b[0;32m   1518\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\n\u001b[0;32m   1519\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1520\u001b[0m     sheet_name: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1538\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds,\n\u001b[0;32m   1539\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, DataFrame] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mint\u001b[39m, DataFrame]:\n\u001b[0;32m   1540\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1541\u001b[0m \u001b[38;5;124;03m    Parse specified sheet(s) into a DataFrame.\u001b[39;00m\n\u001b[0;32m   1542\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1549\u001b[0m \u001b[38;5;124;03m        DataFrame from the passed in Excel file.\u001b[39;00m\n\u001b[0;32m   1550\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1552\u001b[0m \u001b[43m        \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1553\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1556\u001b[0m \u001b[43m        \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1558\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrue_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrue_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfalse_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfalse_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1560\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1561\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1562\u001b[0m \u001b[43m        \u001b[49m\u001b[43mna_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1563\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_parser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1566\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthousands\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthousands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1567\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1568\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskipfooter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipfooter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1569\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1570\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1571\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch-env\\lib\\site-packages\\pandas\\io\\excel\\_base.py:746\u001b[0m, in \u001b[0;36mBaseExcelReader.parse\u001b[1;34m(self, sheet_name, header, names, index_col, usecols, dtype, true_values, false_values, skiprows, nrows, na_values, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, dtype_backend, **kwds)\u001b[0m\n\u001b[0;32m    743\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReading sheet \u001b[39m\u001b[38;5;132;01m{\u001b[39;00masheetname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    745\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(asheetname, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 746\u001b[0m     sheet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_sheet_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43masheetname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# assume an integer if not a string\u001b[39;00m\n\u001b[0;32m    748\u001b[0m     sheet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_sheet_by_index(asheetname)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch-env\\lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:569\u001b[0m, in \u001b[0;36mOpenpyxlReader.get_sheet_by_name\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_sheet_by_name\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 569\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_if_bad_sheet_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbook[name]\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch-env\\lib\\site-packages\\pandas\\io\\excel\\_base.py:597\u001b[0m, in \u001b[0;36mBaseExcelReader.raise_if_bad_sheet_by_name\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    595\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_if_bad_sheet_by_name\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msheet_names:\n\u001b[1;32m--> 597\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWorksheet named \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not found\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Worksheet named '4 bins' not found"
     ]
    }
   ],
   "source": [
    "smiles_df = pd.read_excel(smiles_file, sheet_name= smiles_sheet_name)\n",
    "target_df = pd.read_excel(target_file, sheet_name= target_sheet_name)\n",
    "\n",
    "Nrows, Ncolumns = smiles_df.shape\n",
    "Nconstituents= (Ncolumns-1)//2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d8bab8-591c-4156-8210-7cf2132eea71",
   "metadata": {},
   "source": [
    "# Implementation >>>>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170729f0-6a2c-4404-b27e-ecc676c0d2b3",
   "metadata": {},
   "source": [
    "# Featurization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c1cfb0-c76c-4247-bd56-f9e085090357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionaries to store the output\n",
    "dataX_dict = {}\n",
    "datay_dict = {}\n",
    "\n",
    "# Iterate over the featurizer functions based on the featurizer_style\n",
    "for ff in featurizer_map[featurizer_style]:\n",
    "    # Call the function\n",
    "    dataX, datay = ff(smiles_df, target_df, Nrows, Nconstituents)\n",
    "    \n",
    "    # Store the output in the dictionaries with a unique key\n",
    "    featurizer_name = ff.__name__  # Get the featurizer function name\n",
    "    dataX_dict[featurizer_name] = dataX\n",
    "    datay_dict[featurizer_name] = datay\n",
    "\n",
    "\n",
    "# Create the filename using the featurizer_name variable\n",
    "filename = f\"dataX_dict_4bins_{featurizer_style}.pkl\"\n",
    "# Save the variable to a file\n",
    "with open(rf\"C:\\Users\\grvkr\\Box\\Gaurav Kumar\\Purdue_Work\\SAR_NM\\Scripts\\ML_Framework\\Data_Combined\\Cell_Viability_pickle_files\\{filename}\", 'wb') as file:\n",
    "    pickle.dump(dataX_dict, file)\n",
    "\n",
    "filename = f\"datay_dict_4bins_{featurizer_style}.pkl\"\n",
    "# Save the variable to a file\n",
    "with open(rf\"C:\\Users\\grvkr\\Box\\Gaurav Kumar\\Purdue_Work\\SAR_NM\\Scripts\\ML_Framework\\Data_Combined\\Cell_Viability_pickle_files\\{filename}\", 'wb') as file:\n",
    "    pickle.dump(datay_dict, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05cc299-7d18-4e94-9ca7-9dbc57c7717c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the filename using the featurizer_name variable\n",
    "# filename = f\"dataX_dict_4bins_{featurizer_style}.pkl\"\n",
    "# # Save the variable to a file\n",
    "# with open(rf\"C:\\Users\\grvkr\\Box\\Gaurav Kumar\\Purdue_Work\\SAR_NM\\Scripts\\ML_Framework\\Data_Combined\\Cell_Viability_pickle_files\\{filename}\", 'rb') as file:\n",
    "#     dataX_dict= pickle.load(file)\n",
    "\n",
    "# filename = f\"datay_dict_4bins_{featurizer_style}.pkl\"\n",
    "# # Save the variable to a file\n",
    "# with open(rf\"C:\\Users\\grvkr\\Box\\Gaurav Kumar\\Purdue_Work\\SAR_NM\\Scripts\\ML_Framework\\Data_Combined\\Cell_Viability_pickle_files\\{filename}\", 'rb') as file:\n",
    "#     datay_dict= pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3b17aa-acd4-4207-8e93-a08ae260011c",
   "metadata": {},
   "source": [
    "# Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67955cfc-dc74-4846-a5e8-d507446dfa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Inputs parameters for Train-Test Data Splitting\n",
    "test_ratio= 0.2\n",
    "num_random= 42\n",
    "\n",
    "# Initialize dictionaries to store the output\n",
    "dataX_train_dict = {}\n",
    "dataX_test_dict = {}\n",
    "datay_train_dict = {}\n",
    "datay_test_dict = {}\n",
    "\n",
    "# Iterate over the functions based on the featurizer_style\n",
    "for ff in featurizer_map[featurizer_style]:\n",
    "    featurizer_name = ff.__name__  # Get the featurizer function name\n",
    "    \n",
    "    dataX_train, dataX_test, datay_train, datay_test= train_test_split(dataX_dict[featurizer_name], datay_dict[featurizer_name], test_size= test_ratio, random_state= num_random)\n",
    "    \n",
    "    # Store the output in the dictionaries with a unique key\n",
    "    dataX_train_dict[featurizer_name] = dataX_train\n",
    "    dataX_test_dict[featurizer_name] = dataX_test\n",
    "    datay_train_dict[featurizer_name] = datay_train\n",
    "    datay_test_dict[featurizer_name] = datay_test\n",
    "\n",
    "filename = f\"dataX_train_dict_4bins_{featurizer_style}.pkl\"\n",
    "# Save the variable to a file\n",
    "with open(rf\"C:\\Users\\grvkr\\Box\\Gaurav Kumar\\Purdue_Work\\SAR_NM\\Scripts\\ML_Framework\\Data_Combined\\Cell_Viability_pickle_files\\{filename}\", 'wb') as file:\n",
    "    pickle.dump(dataX_train_dict, file)\n",
    "    \n",
    "filename = f\"datay_train_dict_4bins_{featurizer_style}.pkl\"\n",
    "# Save the variable tdataX_train_dicto a file\n",
    "with open(rf\"C:\\Users\\grvkr\\Box\\Gaurav Kumar\\Purdue_Work\\SAR_NM\\Scripts\\ML_Framework\\Data_Combined\\Cell_Viability_pickle_files\\{filename}\", 'wb') as file:\n",
    "    pickle.dump(datay_train_dict, file)\n",
    "\n",
    "filename = f\"dataX_test_dict_4bins_{featurizer_style}.pkl\"\n",
    "# Save the variable to a file\n",
    "with open(rf\"C:\\Users\\grvkr\\Box\\Gaurav Kumar\\Purdue_Work\\SAR_NM\\Scripts\\ML_Framework\\Data_Combined\\Cell_Viability_pickle_files\\{filename}\", 'wb') as file:\n",
    "    pickle.dump(dataX_test_dict, file)\n",
    "\n",
    "filename = f\"datay_test_dict_4bins_{featurizer_style}.pkl\"\n",
    "# Save the variable to a file\n",
    "with open(rf\"C:\\Users\\grvkr\\Box\\Gaurav Kumar\\Purdue_Work\\SAR_NM\\Scripts\\ML_Framework\\Data_Combined\\Cell_Viability_pickle_files\\{filename}\", 'wb') as file:\n",
    "    pickle.dump(datay_test_dict, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f06e1a-c00b-492e-b574-f54e339473c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = f\"dataX_train_dict_4bins_{featurizer_style}.pkl\"\n",
    "# # Save the variable to a file\n",
    "# with open(rf\"C:\\Users\\grvkr\\Box\\Gaurav Kumar\\Purdue_Work\\SAR_NM\\Scripts\\ML_Framework\\Data_Combined\\Activity_pickle_files\\{filename}\", 'rb') as file:\n",
    "#     dataX_train_dict= pickle.load(file)\n",
    "    \n",
    "# filename = f\"datay_train_dict_4bins_{featurizer_style}.pkl\"\n",
    "# # Save the variable tdataX_train_dicto a file\n",
    "# with open(rf\"C:\\Users\\grvkr\\Box\\Gaurav Kumar\\Purdue_Work\\SAR_NM\\Scripts\\ML_Framework\\Data_Combined\\Activity_pickle_files\\{filename}\", 'rb') as file:\n",
    "#     datay_train_dict= pickle.load(file)\n",
    "\n",
    "# filename = f\"dataX_test_dict_4bins_{featurizer_style}.pkl\"\n",
    "# # Save the variable to a file\n",
    "# with open(rf\"C:\\Users\\grvkr\\Box\\Gaurav Kumar\\Purdue_Work\\SAR_NM\\Scripts\\ML_Framework\\Data_Combined\\Activity_pickle_files\\{filename}\", 'rb') as file:\n",
    "#     dataX_test_dict= pickle.load(file)\n",
    "\n",
    "# filename = f\"datay_test_dict_4bins_{featurizer_style}.pkl\"\n",
    "# # Save the variable to a file\n",
    "# with open(rf\"C:\\Users\\grvkr\\Box\\Gaurav Kumar\\Purdue_Work\\SAR_NM\\Scripts\\ML_Framework\\Data_Combined\\Activity_pickle_files\\{filename}\", 'rb') as file:\n",
    "#     datay_test_dict= pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d633466f-fc24-45d1-b586-a7a4fa22aeac",
   "metadata": {},
   "source": [
    "# ML model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae82edcf-b303-4fa2-a729-0faeb37ed484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for ML model training\n",
    "num_estimators= 200\n",
    "num_neighbors= 5\n",
    "num_random= 42\n",
    "\n",
    "\n",
    "# Initialize dictionaries to store the output\n",
    "datay_pred_dict = {}\n",
    "datay_pred_full_dict = {}\n",
    "\n",
    "# Iterate over the featurizer functions and ml model functions\n",
    "for ff in featurizer_map[featurizer_style]:\n",
    "    featurizer_name = ff.__name__  # Get the featurizer function name\n",
    "    for mm in ml_model_map[ml_model_style]:\n",
    "        ml_model_name = mm.__name__  # Get the ml model function name\n",
    "    \n",
    "        datay_pred, datay_pred_full= mm(dataX_dict[featurizer_name], dataX_train_dict[featurizer_name], dataX_test_dict[featurizer_name], datay_train_dict[featurizer_name], datay_test_dict[featurizer_name], num_estimators, num_neighbors, num_random)\n",
    "        \n",
    "        # Initialize the inner dictionary if it does not exist\n",
    "        if ml_model_name not in datay_pred_dict:\n",
    "            datay_pred_dict[ml_model_name] = {}\n",
    "        if ml_model_name not in datay_pred_full_dict:\n",
    "            datay_pred_full_dict[ml_model_name] = {}\n",
    "            \n",
    "        # Store the output in the dictionaries with a unique key\n",
    "        datay_pred_dict[ml_model_name][featurizer_name] = datay_pred\n",
    "        datay_pred_full_dict[ml_model_name][featurizer_name] = datay_pred_full\n",
    "\n",
    "filename = f\"datay_pred_dict_4bins_{featurizer_style}.pkl\"\n",
    "# Save the variable to a file\n",
    "with open(rf\"C:\\Users\\grvkr\\Box\\Gaurav Kumar\\Purdue_Work\\SAR_NM\\Scripts\\ML_Framework\\Data_Combined\\Cell_Viability_pickle_files\\{filename}\", 'wb') as file:\n",
    "    pickle.dump(datay_pred_dict, file)\n",
    "\n",
    "filename = f\"datay_pred_full_dict_4bins_{featurizer_style}.pkl\"\n",
    "# Save the variable to a file\n",
    "with open(rf\"C:\\Users\\grvkr\\Box\\Gaurav Kumar\\Purdue_Work\\SAR_NM\\Scripts\\ML_Framework\\Data_Combined\\Cell_Viability_pickle_files\\{filename}\", 'wb') as file:\n",
    "    pickle.dump(datay_pred_full_dict, file)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f427376-332c-49ea-baeb-3e70dfc3e5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = f\"datay_pred_dict_4bins_{featurizer_style}.pkl\"\n",
    "# # Save the variable to a file\n",
    "# with open(rf\"C:\\Users\\grvkr\\Box\\Gaurav Kumar\\Purdue_Work\\SAR_NM\\Scripts\\ML_Framework\\Data_Combined\\Activity_pickle_files\\{filename}\", 'rb') as file:\n",
    "#     datay_pred_dict= pickle.load(file)\n",
    "\n",
    "# filename = f\"datay_pred_full_dict_4bins_{featurizer_style}.pkl\"\n",
    "# # Save the variable to a file\n",
    "# with open(rf\"C:\\Users\\grvkr\\Box\\Gaurav Kumar\\Purdue_Work\\SAR_NM\\Scripts\\ML_Framework\\Data_Combined\\Activity_pickle_files\\{filename}\", 'rb') as file:\n",
    "#     datay_pred_full_dict= pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a446a7-7346-434e-a2c0-ae482fbe1c57",
   "metadata": {},
   "source": [
    "# Write Classification Report to Excel File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d422f1c-9c76-4070-9ffe-14980605207f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Initialize an empty list to store all the rows\n",
    "all_rows = []\n",
    "\n",
    "# Iterate over the functions based on the featurizer_style to process classification report\n",
    "for mm in ml_model_map[ml_model_style]:\n",
    "    ml_model_name = mm.__name__  # Get the function name\n",
    "    for ff in featurizer_map[featurizer_style]:\n",
    "        featurizer_name = ff.__name__  # Get the function name\n",
    "\n",
    "        predictions= datay_pred_dict[ml_model_name][featurizer_name]\n",
    "        y_true = datay_test_dict[featurizer_name]\n",
    "\n",
    "        # Generate classification report\n",
    "        report_dict= classification_report(y_true, predictions, output_dict=True)\n",
    "        # Convert the classification report to a DataFrame\n",
    "        report_df = pd.DataFrame(report_dict).transpose()\n",
    "\n",
    "        # Flatten the DataFrame into a single row for headers and values\n",
    "        flattened_report = report_df.reset_index().melt(id_vars=['index'])\n",
    "        flattened_report.columns = ['Metric', 'Class', 'Value']\n",
    "        # Prepare headers and values for output\n",
    "        headers = flattened_report.apply(lambda row: f\"{row['Class']}_{row['Metric']}\", axis=1)\n",
    "        values = flattened_report['Value']\n",
    "        # Output headers and values as a single row\n",
    "        headers_row = headers.tolist()\n",
    "        headers_row = [\"ML Model Name\"] + [\"Featurizer Name\"] + headers_row\n",
    "        values_row = [ml_model_name] + [featurizer_name] + values.tolist()\n",
    "        \n",
    "        # Create a DataFrame with the headers and values as a single row\n",
    "        output_df = pd.DataFrame([values_row], columns=headers_row)\n",
    "        all_rows.append(output_df)\n",
    "\n",
    "# Concatenate all the rows into a single DataFrame\n",
    "new_data_df = pd.concat(all_rows, ignore_index=True)\n",
    "\n",
    "# Check if the output file exists and read existing data if it does\n",
    "if os.path.exists(output_file):\n",
    "    with pd.ExcelFile(output_file, engine='openpyxl') as xls:\n",
    "        if cr_sheet_name in xls.sheet_names:\n",
    "            existing_data_df = pd.read_excel(xls, sheet_name=cr_sheet_name)\n",
    "            # Concatenate existing data with new data\n",
    "            combined_df = pd.concat([existing_data_df, new_data_df], ignore_index=True)\n",
    "        else:\n",
    "            combined_df = new_data_df\n",
    "else:\n",
    "    combined_df = new_data_df\n",
    "\n",
    "with pd.ExcelWriter(output_file, engine='openpyxl', mode='a', if_sheet_exists= 'replace') as writer:\n",
    "    combined_df.to_excel(writer, sheet_name= cr_sheet_name, index=False)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Finished\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ba7dd1-5b08-45d1-8d8a-526b686c6113",
   "metadata": {},
   "source": [
    "# Write Predicted value to Excel File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5d2779-7620-465d-a431-b2f943e4ae0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a DataFrame to store the predictions\n",
    "new_output_df = pd.DataFrame()\n",
    "column_name= 'y Test'\n",
    "new_output_df[column_name] = datay_test_dict[featurizer_name]\n",
    "# Iterate over the ml model functions and featurizer functions\n",
    "for ml_model_name, featurizers in datay_pred_dict.items():\n",
    "    for featurizer_name, predictions in featurizers.items():\n",
    "        # Create a column name based on ml_model_name and featurizer_name\n",
    "        column_name = f\"{ml_model_name}_{featurizer_name}\"\n",
    "        # Add the predictions to the DataFrame\n",
    "        new_output_df[column_name] = predictions\n",
    "# Check if the output file exists and read existing data if it does\n",
    "if os.path.exists(output_file):\n",
    "    with pd.ExcelFile(output_file, engine='openpyxl') as xls:\n",
    "        if ypred_sheet_name in xls.sheet_names:\n",
    "            existing_data_df = pd.read_excel(xls, sheet_name=ypred_sheet_name)\n",
    "            # Concatenate existing data with new data\n",
    "            combined_df = pd.concat([existing_data_df, new_output_df], axis=1)\n",
    "        else:\n",
    "            combined_df = new_output_df\n",
    "else:\n",
    "    combined_df = new_output_df\n",
    "\n",
    "# Write the combined DataFrame to the Excel file\n",
    "with pd.ExcelWriter(output_file, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    combined_df.to_excel(writer, sheet_name=ypred_sheet_name, index=False)\n",
    "\n",
    "\n",
    "\n",
    "# Initialize a DataFrame to store the predictions\n",
    "new_output_full_df = pd.DataFrame()\n",
    "column_name= 'y Full'\n",
    "new_output_full_df[column_name] = datay_dict[featurizer_name]\n",
    "# Iterate over the ml model functions and featurizer functions\n",
    "for ml_model_name, featurizers in datay_pred_full_dict.items():\n",
    "    for featurizer_name, predictions in featurizers.items():\n",
    "        # Create a column name based on ml_model_name and featurizer_name\n",
    "        column_name = f\"{ml_model_name}_{featurizer_name}\"\n",
    "        # Add the predictions to the DataFrame\n",
    "        new_output_full_df[column_name] = predictions\n",
    "# Check if the output file exists and read existing data if it does\n",
    "if os.path.exists(output_file):\n",
    "    with pd.ExcelFile(output_file, engine='openpyxl') as xls:\n",
    "        if ypred_sheet_name in xls.sheet_names:\n",
    "            existing_data_df = pd.read_excel(xls, sheet_name=ypred_full_sheet_name)\n",
    "            # Concatenate existing data with new data\n",
    "            combined_df = pd.concat([existing_data_df, new_output_full_df], axis=1)\n",
    "        else:\n",
    "            combined_df = new_output_full_df\n",
    "else:\n",
    "    combined_df = new_output_full_df\n",
    "\n",
    "# Write the combined DataFrame to the Excel file\n",
    "with pd.ExcelWriter(output_file, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    combined_df.to_excel(writer, sheet_name=ypred_full_sheet_name, index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee11d776-2abb-4c0f-9d57-69a5502304b3",
   "metadata": {},
   "source": [
    "# Calculate Accuracy for each class and Write to excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7e9d54-5e44-4637-acd9-24a4a2d5e9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Calculate accuracy for each class\n",
    "\n",
    "\n",
    "# Initialize an empty dictionary to store the accuracies\n",
    "accuracy_dict = {}\n",
    "precision_dict = {}\n",
    "recall_dict = {}\n",
    "f1score_dict = {}\n",
    "\n",
    "# Iterate over the functions based on the featurizer_style to process classification report\n",
    "for mm in ml_model_map[ml_model_style]:\n",
    "    ml_model_name = mm.__name__  # Get the function name\n",
    "    accuracy_dict[ml_model_name] = {}\n",
    "    precision_dict[ml_model_name] = {}\n",
    "    recall_dict[ml_model_name] = {}\n",
    "    f1score_dict[ml_model_name] = {}\n",
    "    for ff in featurizer_map[featurizer_style]:\n",
    "        featurizer_name = ff.__name__  # Get the function name\n",
    "        predicted_class= datay_pred_dict[ml_model_name][featurizer_name]\n",
    "        true_class = datay_test_dict[featurizer_name]\n",
    "        \n",
    "        classes = np.unique(true_class)\n",
    "        accuracy_per_class = {}\n",
    "        precision_per_class = {}\n",
    "        recall_per_class = {}\n",
    "        f1score_per_class = {}\n",
    "        for cls in classes:\n",
    "            # Binary classification: 1 for current class, 0 for all other classes\n",
    "            y_true_binary = [1 if y == cls else 0 for y in true_class]\n",
    "            y_pred_binary = [1 if y == cls else 0 for y in predicted_class]\n",
    "            accuracy = accuracy_score(y_true_binary, y_pred_binary)\n",
    "            precision = precision_score(y_true_binary, y_pred_binary)\n",
    "            recall = recall_score(y_true_binary, y_pred_binary)\n",
    "            f1score = f1_score(y_true_binary, y_pred_binary)\n",
    "            \n",
    "            accuracy_per_class[cls] = accuracy\n",
    "            precision_per_class[cls] = precision\n",
    "            recall_per_class[cls] = recall\n",
    "            f1score_per_class[cls] = f1score\n",
    "\n",
    "        accuracy_dict[ml_model_name][featurizer_name] = accuracy_per_class\n",
    "        precision_dict[ml_model_name][featurizer_name] = precision_per_class\n",
    "        recall_dict[ml_model_name][featurizer_name] = recall_per_class\n",
    "        f1score_dict[ml_model_name][featurizer_name] = f1score_per_class\n",
    "\n",
    "# Convert the nested dictionary to a DataFrame\n",
    "accuracy_df = pd.DataFrame.from_dict({(i,j): accuracy_dict[i][j] \n",
    "                                       for i in accuracy_dict.keys() \n",
    "                                       for j in accuracy_dict[i].keys()},\n",
    "                                      orient='index')\n",
    "# Reset the index to make ml_model_name and featurizer_name columns\n",
    "accuracy_df.reset_index(inplace=True)\n",
    "accuracy_df.columns = ['ML Model Name', 'Featurizer Name'] + list(accuracy_df.columns[2:])\n",
    "\n",
    "\n",
    "precision_df = pd.DataFrame.from_dict({(i,j): precision_dict[i][j] \n",
    "                                       for i in precision_dict.keys() \n",
    "                                       for j in precision_dict[i].keys()},\n",
    "                                      orient='index')\n",
    "# Reset the index to make ml_model_name and featurizer_name columns\n",
    "precision_df.reset_index(inplace=True)\n",
    "precision_df.columns = ['ML Model Name', 'Featurizer Name'] + list(precision_df.columns[2:])\n",
    "\n",
    "\n",
    "recall_df = pd.DataFrame.from_dict({(i,j): recall_dict[i][j] \n",
    "                                       for i in recall_dict.keys() \n",
    "                                       for j in recall_dict[i].keys()},\n",
    "                                      orient='index')\n",
    "# Reset the index to make ml_model_name and featurizer_name columns\n",
    "recall_df.reset_index(inplace=True)\n",
    "recall_df.columns = ['ML Model Name', 'Featurizer Name'] + list(recall_df.columns[2:])\n",
    "\n",
    "\n",
    "f1score_df = pd.DataFrame.from_dict({(i,j): f1score_dict[i][j] \n",
    "                                       for i in f1score_dict.keys() \n",
    "                                       for j in f1score_dict[i].keys()},\n",
    "                                      orient='index')\n",
    "# Reset the index to make ml_model_name and featurizer_name columns\n",
    "f1score_df.reset_index(inplace=True)\n",
    "f1score_df.columns = ['ML Model Name', 'Featurizer Name'] + list(f1score_df.columns[2:])\n",
    "\n",
    "\n",
    "# Check if the output file exists and read existing data if it does\n",
    "if os.path.exists(output_file):\n",
    "    with pd.ExcelFile(output_file, engine='openpyxl') as xls:\n",
    "        if accuracy_sheet_name in xls.sheet_names:\n",
    "            existing_data_df = pd.read_excel(xls, sheet_name=accuracy_sheet_name)\n",
    "            # Concatenate existing data with new data\n",
    "            combined_df = pd.concat([existing_data_df, accuracy_df], ignore_index=True)\n",
    "        else:\n",
    "            combined_df = accuracy_df\n",
    "else:\n",
    "    combined_df = accuracy_df\n",
    "\n",
    "# Write the combined DataFrame to the Excel file\n",
    "with pd.ExcelWriter(output_file, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    combined_df.to_excel(writer, sheet_name=accuracy_sheet_name, index=False)\n",
    "\n",
    "\n",
    "# Check if the output file exists and read existing data if it does\n",
    "if os.path.exists(output_file):\n",
    "    with pd.ExcelFile(output_file, engine='openpyxl') as xls:\n",
    "        if precision_sheet_name in xls.sheet_names:\n",
    "            existing_data_df = pd.read_excel(xls, sheet_name=precision_sheet_name)\n",
    "            # Concatenate existing data with new data\n",
    "            combined_df = pd.concat([existing_data_df, precision_df], ignore_index=True)\n",
    "        else:\n",
    "            combined_df = precision_df\n",
    "else:\n",
    "    combined_df = precision_df\n",
    "\n",
    "# Write the combined DataFrame to the Excel file\n",
    "with pd.ExcelWriter(output_file, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    combined_df.to_excel(writer, sheet_name=precision_sheet_name, index=False)\n",
    "\n",
    "\n",
    "# Check if the output file exists and read existing data if it does\n",
    "if os.path.exists(output_file):\n",
    "    with pd.ExcelFile(output_file, engine='openpyxl') as xls:\n",
    "        if recall_sheet_name in xls.sheet_names:\n",
    "            existing_data_df = pd.read_excel(xls, sheet_name=recall_sheet_name)\n",
    "            # Concatenate existing data with new data\n",
    "            combined_df = pd.concat([existing_data_df, recall_df], ignore_index=True)\n",
    "        else:\n",
    "            combined_df = recall_df\n",
    "else:\n",
    "    combined_df = recall_df\n",
    "\n",
    "# Write the combined DataFrame to the Excel file\n",
    "with pd.ExcelWriter(output_file, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    combined_df.to_excel(writer, sheet_name=recall_sheet_name, index=False)\n",
    "\n",
    "\n",
    "# Check if the output file exists and read existing data if it does\n",
    "if os.path.exists(output_file):\n",
    "    with pd.ExcelFile(output_file, engine='openpyxl') as xls:\n",
    "        if f1score_sheet_name in xls.sheet_names:\n",
    "            existing_data_df = pd.read_excel(xls, sheet_name=f1score_sheet_name)\n",
    "            # Concatenate existing data with new data\n",
    "            combined_df = pd.concat([existing_data_df, f1score_df], ignore_index=True)\n",
    "        else:\n",
    "            combined_df = f1score_df\n",
    "else:\n",
    "    combined_df = f1score_df\n",
    "\n",
    "# Write the combined DataFrame to the Excel file\n",
    "with pd.ExcelWriter(output_file, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    combined_df.to_excel(writer, sheet_name=f1score_sheet_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5af89e-49dd-4de4-b575-a5aeba99d9ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
